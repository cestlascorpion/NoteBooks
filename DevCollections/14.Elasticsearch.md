# Elasticsearch

## 补充

### 倒排索引

倒排索引又叫反向索引（右下图）以字或词为文档中出现的位置情况。

![InvertedIndex](../Resource/InvertedIndex.jpg)

在实际的运用中，我们可以对数据库中原始的数据结构（左图），在业务空闲时事先根据左图内容，创建新的倒排索引结构的数据区域（右图）。用户有查询需求时，先访问倒排索引数据区域（右图），得出文档 id 后，通过文档 id 即可快速，准确的通过左图找到具体的文档内容。

### Lucene

Lucene 是一套用于全文检索和搜寻的开源程序库，由 Apache 软件基金会支持和提供。Lucene 提供了一个简单却强大的应用程序接口（API），能够做全文索引和搜寻，在 Java 开发环境里 Lucene 是一个成熟的免费开放源代码工具。另外，它的分布式设计让它天生就适合用于云计算中，并能够达到准实时搜索，而且安装使用方便，还拥有稳定，可靠，快速等特性。Lucene 并不是现成的搜索引擎产品，但可以用来制作搜索引擎产品。

全文检索即对文档中全部内容进行分词，然后对所有单词建立倒排索引的过程。

Lucene：底层的 API，工具包；Solr：基于 Lucene 开发的企业级的搜索引擎产品；Elasticsearch：基于 Lucene 开发的企业级的搜索引擎产品。

Lucene 只是一个库。想要使用它，你必须使用 Java 来作为开发语言并将其直接集成到你的应用中，更糟糕的是，Lucene 非常复杂，你需要深入了解检索的相关知识来理解它是如何工作的。Elasticsearch 也使用 Java 开发并使用 Lucene 作为其核心来实现所有索引和搜索的功能，但是它的目的是通过简单的 RESTful API 来隐藏 Lucene 的复杂性，从而让全文搜索变得简单。

## 概述

Elasticsearch 是一个开源的高扩展的分布式全文检索引擎，它可以近乎实时的存储、检索数据；本身扩展性很好，可以扩展到上百台服务器，处理 PB 级别的数据。

Elasticsearch 也使用 Java 开发并使用 Lucene 作为其核心来实现所有索引和搜索的功能，但是它的目的是通过简单的 RESTful API 来隐藏 Lucene 的复杂性，从而让全文搜索变得简单。

## 基本概念

Cluster：集群。ES 可以作为一个独立的单个搜索服务器。不过为了处理大型数据集，实现容错和高可用性，ES 可以运行在许多互相合作的服务器上。这些服务器的集合称为集群。

Node：节点。形成集群的每个服务器称为节点。

Shard：分片。当有大量的文档时，由于内存的限制、磁盘处理能力不足、无法足够快的响应客户端的请求等，一个节点可能不够。这种情况下，数据可以分为较小的分片。每个分片放到不同的服务器上。 当查询的索引分布在多个分片上时，ES 会把查询发送给每个相关的分片，并将结果组合在一起，而应用程序并不知道分片的存在。即该过程对用户来说是透明的。

Replia：副本。为提高查询吞吐量或实现高可用性，可以使用分片副本。 副本是一个分片的精确复制，每个分片可以有零个或多个副本。ES 中可以有许多相同的分片，其中之一被选择更改索引操作，这种特殊的分片称为主分片。 当主分片丢失时，如：该分片所在的数据不可用时，集群将副本提升为新的主分片。

## 对比关系型数据库

![ESvsMysql](../Resource/ESvsMysql.png)

>- 关系型数据库中的数据库（DataBase），等价于 ES 中的索引（Index）。
>- 一个数据库下面有 N 张表（Table），等价于 1 个索引 Index 下面有 N 多类型（Type）。
>- 一个数据库表（Table）下的数据由多行（ROW）多列（column，属性）组成，等价于 1 个 Type 由多个文档（Document）和多 Field 组成。
>- 在一个关系型数据库里面，schema 定义了表、每个表的字段，还有表和字段之间的关系。 与之对应的，在 ES 中：Mapping 定义索引下的 Type 的字段处理规则，即索引如何建立、索引类型、是否保存原始索引 JSON 文档、是否压缩原始 JSON 文档、是否需要分词处理、如何进行分词处理等。
>- 在数据库中的增 insert、删 delete、改 update、查 search 操作等价于 ES 中的增 PUT/POST、删 Delete、改 _update、查 GET。

## ELK

ELK=elasticsearch+Logstash+kibana

elasticsearch：后台分布式存储以及全文检索；logstash: 日志加工、搬运工；kibana：数据可视化展示。

ELK 架构为数据分布式存储、可视化查询和日志解析创建了一个功能强大的管理链。 三者相互配合，取长补短，共同完成分布式大数据处理工作。

## 特点和优势

>- 分布式实时文件存储，可将每一个字段存入索引，使其可以被检索到。
>- 实时分析的分布式搜索引擎。
>- 索引分拆成多个分片，每个分片可有零个或多个副本。集群中的每个数据节点都可承载一个或多个分片，并且协调和处理各种操作；负载再平衡和路由在大多数情况下自动完成。
>- 可以扩展到上百台服务器，处理 PB 级别的结构化或非结构化数据。也可以运行在单台 PC 上（已测试）。
>- 支持插件机制，分词插件、同步插件、Hadoop 插件、可视化插件等。

## 对比 (Sphinx+Mysql)

导入 MySQL 数据生成索引。Elastic Search：RESTful 接口；Sphinx：原生支持基于 MySQL 的表建索引。Elastic Search 官方文档上，数据都是使用 RESTful 接口一条一条插入的，也就是增量更新。有个 bulk 接口，可以批量导入、大幅加快速度。在数据量非常大的时候，遍历全表重建一次索引会比较消耗时间。在导入 MySQL 数据生成索引时，从易用性、可靠性、速度上来看，Sphinx 优于 Elastic Search。Sphinx 真的很快。

增量更新支持。Elastic Search 优于 Sphinx。Elastic Search 把增量更新作为首选 CURD 方式；而 Sphinx 使用辅助表的方案不但不优雅，还会让你的其他系统变得复杂起来，在你频繁更改单条数据的时候很容易出错。

可视化与辅助工具。Elastic Search 优于 Sphinx。Kibana，Elastic Search 提供的数据可视化界面。Beats，一套收集日志的框架。Logstash，一套日志处理框架。Sphinx Tools，还停留在性能监控的阶段。

搜索算法支持。ElasthcSearch 的搜索底层功能基于 Lucene，Sphinx 也该有的都有。然而 Elastic Search 的 Query DSL 支持更复杂的查询逻辑，这一点是超越 Sphinx 的。在自定义 Ranker 方面，Elastic Search 的 Function Score Query 比 Sphinx 的 expression-ranker 强大许多。总的来说，Elastic Search 稍微优于 Sphinx。

横向扩展与高可用。Elastic Search 是天生为了集群化而设计的，还支持动态加机器，还可以轻松的和 Nginx 等各类中间件实现负载均衡。Sphinx 可以实现分布式，但是比较复杂。

资源占用。Sphinx 优于 Elastic Search。无论是 CPU 还是内存占用，Sphinx 都比 Elastic Search 优秀。一些高并发的简单需求会选择 Sphinx。

搜索速度。搜索速度主要看怎么配置 Cluster，越多搜起来就越快。

如果有定制 Ranker 的需求，Elastic Search 的 Functional Score Query 可以满足；Elastic Search 有更强的横向扩展能力和高可用性；Kibana 整出好看的报表。Elastic Search 发力非常猛，版本迭代如火箭一般，社区也很活跃。

通常可以使用 ES 来实现自己的站内搜索引擎，但还是推荐使用 MySQL 来做原始数据的存储，然后基于 MySQL 在上层部署 ES 中间件来实现所需的搜索引擎。MySQL 虽然在数据全文检索方面显得有些力不从心，但是因为它的事务功能特性，可以保证不会出现脏数据。而 ES 对事务方面并无建树，所以不是很适合存储原始数据。当然也可以运用双写的策略，一方面利用 MySQL 保证原始数据的安全性，另一方面，利用 ES 的搜索力量。

## 实战

```shell
# 健康状况
# green 表示正常
# red 表示不是所有主分片都可用
# yellow 表示所有主分片可用，但不是所有副本分片都可用，常见于单节点的集群
curl -XGET 'localhost:9200/_cat/health?v'
# 索引状况 closed 表示被关闭但未删除
curl -XGET 'localhost:9200/_cat/indices?v'
# 删除索引
curl -XDELETE 'localhost:9200/new-index?pretty'
# 添加索引
curl -XPUT 'localhost:9200/new-index?pretty'
# 添加文档 ID 不能重复 否则会覆盖
# 如果不指定 ID 系统会生成一个，比如  "_id" : "sA5-9nABEPdMcnXNNwus",
curl -H "Content-Type:application/json" -XPOST 'localhost:9200/man/young/5?pretty' -d '{"name":"Leo","age":26}'
# 修改内容 POST 修改某个属性（_update+"doc"）；PUT 必须带上所有字段
# 部分更新与全量更新的原理相似：添加和标记删除，部分更新开销更小，更快（指在 shard 内部完成修改）
curl -H "Content-Type:application/json" -XPOST 'localhost:9200/man/young/5/_update?pretty' -d '{"doc":{"age":22}}'
curl -H "Content-Type:application/json" -XPUT 'localhost:9200/man/young/5?pretty' -d '{"name":"Leo","age":26,"about":"EJ himself"}'
# 搜素所有
curl -XGET 'localhost:9200/man/young/_search?pretty'
curl -H "Content-Type:application/json" -XPOST 'localhost:9200/man/young/_search?pretty' -d '{
  "query":{
    "match_all":{}
  }
}'
# 添加搜索的关键词
curl -XGET 'localhost:9200/man/young/_search?pretty&q=ian'
curl -H "Content-Type:application/json" -XPOST 'localhost:9200/man/young/_search?pretty' -d '{
  "query":{
    "match":{
      "age":26
    }
  }
}'
# 分页 es 取所有分片的前 from+size 个结果，汇总后取 size 个展示
# 因此越取后面的内容，耗时越长，排名也越不靠谱
curl -H "Content-Type:application/json" -XPOST 'localhost:9200/man/young/_search?pretty' -d '{
  "query":{
    "match_all":{}
  },
  "from":0,
  "size":1
}'
# 过滤结果的字段 _source
curl -H "Content-Type:application/json" -XPOST 'localhost:9200/man/young/_search?pretty' -d '{
  "query":{
    "match_all":{}},
    "_source":[
      "name"
    ],
  "from":2,
  "size":2
}'
# 添加条件 必须年龄为 26，名字的字典序大于 "ian"
# must 必须匹配 shoud 可选匹配 must_not 必须不匹配
curl -H "Content-Type:application/json" -XPOST 'localhost:9200/man/young/_search?pretty' -d '{
  "query":{
    "bool":{
      "must":{
        "match":{
          "age":26
        }
      },
      "filter":{
        "range":{
          "name":{
            "gt":"ian"
          }
        }
      }
    }
  }
}'
# match 全文检索 match_phrase 匹配短语
curl -H "Content-Type:application/json" -XPOST 'localhost:9200/man/young/_search?pretty' -d '{
  "query":{
    "match_phrase":{
      "about":"fan of Lady gaga"
    }
  }
}'
# 高亮关键字 <em>lady</em> <em>gaga</em>
curl -H "Content-Type:application/json" -XPOST 'localhost:9200/man/young/_search?pretty' -d '{
  "query":{
    "match":{
      "about":"Lady gaga"
    }
  },
  "highlight":{
    "fields":{
      "about":{}
    }
  }
}'
```

## 元数据

元数据 (Metadata)，又称中介数据、中继数据，为描述数据的数据 (data about data)，主要是描述数据属性 (property) 的信息，用来支持如指示存储位置、历史数据、资源查找、文件记录等功能。元数据算是一种电子式目录，为了达到编制目录的目的，必须在描述并收藏数据的内容或特色，进而达成协助数据检索的目的。元数据是关于数据的组织、数据域及其关系的信息，简言之，元数据就是关于数据的数据。

### _index

代表一个 document 存储在哪个 index 中。类似的数据（document）放在同一个 index，不同类型的数据放在不同的 index。索引名必须是小写，不能用下划线（_）开头，不能包含逗号。

### _type

代表 document 属于 index 下 的哪个类别（type）。一个 index 通常包含多个 type。type 名称可以大写或小写，不能用下划线（_）开头，不能包含逗号。

### _id

代表 document 的唯一标识，与 index 和 type 一起确定一个唯一的 document。可以手动指定，也可 es 自动生成。手动指定：PUT /index/type/id 自动生成： PUT /index/type/ 生成 base64 编码的 20 长度的字符串 ID，URL 安全，分布式集群下不可能重复。一般来说，是从某些其他的系统中，导入一些数据到 es 时，会采取这种方式，就是使用系统中已有数据的唯一标识，作为 es 中的 document id。对于日志的搜集使用自动的 document id 是比较适合的。

### _score

相关度分数：匹配程度，分数越高越相关。

### _source

代表一个 document，是一个 json 对象（{json}），包含一个实例对象。

## 聚合分析

根据 age 的值分组，需要将 age 的 fielddata 属性设置为 true。不支持聚合后分页。聚合后不能分页，但能分区来取。性能：聚合分页会在大量的记录中产生性能问题。正确性：聚合的文档计数不准确。

```shell
curl -H "Content-Type:application/json" -XPUT 'localhost:9200/man/_mapping/young?pretty' -d '{
  "properties":{
    "interests":{
      "type":"text",
      "fielddata":true
    }
  }
}'
# size=0 只展示聚合结果 group_by_age 聚合命名 field 分组值
curl -H "Content-Type:application/json" -XPOST 'localhost:9200/man/young/_search?pretty' -d '{
  "size":0,
  "aggs":{
    "group_by_age":{
      "terms":{
        "field":"age"
      }
    }
  }
}'
{
  "took" : 26,
  "timed_out" : false,
  "_shards" : {
    "total" : 5,
    "successful" : 5,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : 5,
    "max_score" : 0.0,
    "hits" : [ ]
  },
  "aggregations" : {
    "group_by_age" : {
      "doc_count_error_upper_bound" : 0,
      "sum_other_doc_count" : 0,
      "buckets" : [
        {
          "key" : 26,
          "doc_count" : 2
        },
        {
          "key" : 21,
          "doc_count" : 1
        },
        {
          "key" : 22,
          "doc_count" : 1
        },
        {
          "key" : 27,
          "doc_count" : 1
        }
      ]
    }
  }
}

# 搜索结果进行聚集
curl -H "Content-Type:application/json" -XPOST 'localhost:9200/man/young/_search?pretty' -d '{
  "size":0,
  "query":{
    "match":{
      "about":"EJ"
    }
  },
  "aggs":{
    "group_by_age":{
      "terms":{
        "field":"age"
      }
    }
  }
}'
{
  "took" : 1,
  "timed_out" : false,
  "_shards" : {
    "total" : 5,
    "successful" : 5,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : 2,
    "max_score" : 0.0,
    "hits" : [ ]
  },
  "aggregations" : {
    "group_by_age" : {
      "doc_count_error_upper_bound" : 0,
      "sum_other_doc_count" : 0,
      "buckets" : [
        {
          "key" : 21,
          "doc_count" : 1
        },
        {
          "key" : 22,
          "doc_count" : 1
        }
      ]
    }
  }
}

# 求 age 的平均值
curl -H "Content-Type:application/json" -XPOST 'localhost:9200/man/young/_search?pretty' -d '{
  "size":0,
  "aggs":{
    "avg_age":{
      "avg":{
        "field":"age"
      }
    }
  }
}'
{
  "took" : 4,
  "timed_out" : false,
  "_shards" : {
    "total" : 5,
    "successful" : 5,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : 5,
    "max_score" : 0.0,
    "hits" : [ ]
  },
  "aggregations" : {
    "avg_age" : {
      "value" : 24.4
    }
  }
}
```

## 分页方式

### from+size 浅分页

" 浅 " 分页可以理解为简单意义上的分页。它的原理很简单，就是查询前 20 条数据，然后截断前 10 条，只返回 10-20 的数据。这样其实白白浪费了前 10 条的查询。from 定义了目标数据的偏移值，size 定义当前返回的数目。默认 from 为 0，size 为 10，即所有的查询默认仅仅返回前 10 条数据。

es 是基于分片的，假设有 5 个分片，from=100，size=10。则会根据排序规则从 5 个分片中各取回 100 条数据数据，然后汇总成 500 条数据后选择最后面的 10 条数据。越往后的分页，执行的效率越低。总体上会随着 from 的增加，消耗时间也会增加。而且数据量越大，就越明显！

```shell
curl -H "Content-Type:application/json" -XGET 'localhost:9200/man/young/_search?pretty' -d '{
  "query": {
    "match_all":{}
  },
  "size": 2,
  "from": 2,
  "sort": [
    {"age": {"order": "desc"}}
  ]
}'
```

### scroll 深分页

from+size 查询在 10000-50000 条数据（1000 到 5000 页）以内的时候还是可以的，但是如果数据过多的话，就会出现深分页问题。

为了解决上面的问题，elasticsearch 提出了一个 scroll 滚动的方式。scroll 类似于 sql 中的 cursor，使用 scroll，每次只能获取一页的内容，然后会返回一个 scroll_id。根据返回的这个 scroll_id 可以不断地获取下一页的内容，所以 scroll 并不适用于有跳页的情景。

```shell
# XGET/XPOT 均可
curl -H "Content-Type:application/json" -XPOST 'localhost:9200/man/young/_search?scroll=5m&pretty' -d '{
  "query": {
    "match_all":{}
  },
  "size": 2,
  "sort": [
    {"age": {"order": "desc"}}
  ]
}'

{
  "_scroll_id" : "DnF1ZXJ5VGhlbkZldGNoBQAAAAAAAAIoFjdqUklNTGxnVC1tVjUySTh2VlU0QUEAAAAAAAACJxY3alJJTUxsZ1QtbVY1Mkk4dlZVNEFBAAAAAAAAAioWN2pSSU1MbGdULW1WNTJJOHZWVTRBQQAAAAAAAAIpFjdqUklNTGxnVC1tVjUySTh2VlU0QUEAAAAAAAACKxY3alJJTUxsZ1QtbVY1Mkk4dlZVNEFB",
  "took" : 3,
  "timed_out" : false,
  "_shards" : {
    "total" : 5,
    "successful" : 5,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : 5,
    "max_score" : null,
    "hits" : [
      {
        "_index" : "man",
        "_type" : "young",
        "_id" : "1",
        "_score" : null,
        "_source" : {
          "name" : "Ian",
          "age" : 27,
          "about" : "fan of lady gaga"
        },
        "sort" : [
          27
        ]
      },
      {
        "_index" : "man",
        "_type" : "young",
        "_id" : "2",
        "_score" : null,
        "_source" : {
          "name" : "Hans",
          "age" : 26,
          "about" : "fan of lady gaga and cardi b"
        },
        "sort" : [
          26
        ]
      }
    ]
  }
}

# scroll=5m 表示设置 scroll_id 保留 5 分钟可用，每次请求必须设置，否则保留时长会重置。
# 使用 scroll 必须要将 from 设置为 0。
# size 决定后面每次调用 _search 搜索返回的数量。
# 注意：请求的接口不再使用索引名了，而是 _search/scroll，其中 GET 和 POST 方法都可以使用。
# scroll 的搜索上下文会在 scroll 的保留时间截止后自动清除，但是我们知道 scroll 是非常消耗资源的，所以一个建议就是当不需要了 scroll 数据的时候，尽可能快的把 scroll_id 显式删除掉。
curl -H "Content-Type:application/json" -XPOST 'localhost:9200/_search/scroll?pretty' -d '{
  "scroll":"5m",
  "scroll_id": "DnF1ZXJ5VGhlbkZldGNoBQAAAAAAAAJeFjdqUklNTGxnVC1tVjUySTh2VlU0QUEAAAAAAAACXxY3alJJTUxsZ1QtbVY1Mkk4dlZVNEFBAAAAAAAAAmAWN2pSSU1MbGdULW1WNTJJOHZWVTRBQQAAAAAAAAJhFjdqUklNTGxnVC1tVjUySTh2VlU0QUEAAAAAAAACYhY3alJJTUxsZ1QtbVY1Mkk4dlZVNEFB"
}'

# scroll_id=_all 时删除全部的 scroll
curl -XDELETE 'localhost:9200/_search/scroll/DnF1ZXJ5VGhlbkZldGNoBQAAAAAAAAIoFjdqUklNTGxnVC1tVjUySTh2VlU0QUEAAAAAAAACJxY3alJJTUxsZ1QtbVY1Mkk4dlZVNEFBAAAAAAAAAioWN2pSSU1MbGdULW1WNTJJOHZWVTRBQQAAAAAAAAIpFjdqUklNTGxnVC1tVjUySTh2VlU0QUEAAAAAAAACKxY3alJJTUxsZ1QtbVY1Mkk4dlZVNEFB?pretty'
```

### search_after 深分页

scroll 的方式，官方的建议不用于实时的请求（一般用于数据导出），因为每一个 scroll_id 不仅会占用大量的资源，而且会生成历史快照，对于数据的变更不会反映到快照上。

search_after 分页的方式是根据上一页的最后一条数据来确定下一页的位置，同时在分页请求的过程中，如果有索引数据的增删改查，这些变更也会实时的反映到游标上。但是需要注意，因为每一页的数据依赖于上一页最后一条数据，所以无法跳页请求。

为了找到每一页最后一条数据，每个文档必须有一个全局唯一值，官方推荐使用 _uid 作为全局唯一值，其实使用业务层的 id 也可以。

```shell
curl -H "Content-Type:application/json" -XPOST 'localhost:9200/man/young/_search?pretty' -d '{
  "query": {
    "match_all":{}
  },
  "size": 2,
  "sort": [
    {"_id": {"order": "desc"}}
  ]
}'

{
  "took" : 1,
  "timed_out" : false,
  "_shards" : {
    "total" : 5,
    "successful" : 5,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : 5,
    "max_score" : null,
    "hits" : [
      {
        "_index" : "man",
        "_type" : "young",
        "_id" : "5",
        "_score" : null,
        "_source" : {
          "name" : "Leo",
          "age" : 22,
          "about" : "Ej himself"
        },
        "sort" : [
          "5"
        ]
      },
      {
        "_index" : "man",
        "_type" : "young",
        "_id" : "4",
        "_score" : null,
        "_source" : {
          "name" : "Tian",
          "age" : 21,
          "about" : "fan of EJ"
        },
        "sort" : [
          "4"
        ]
      }
    ]
  }
}
# 使用 search_after 必须要设置 from=0。
# 使用 _id 作为唯一值排序。
# 在返回的最后一条数据里拿到 sort 属性的值传入到 search_after。
# 返回的始终是最新的数据，在分页过程中数据的位置可能会有变更。
curl -H "Content-Type:application/json" -XPOST 'localhost:9200/man/young/_search?pretty' -d '{
  "query": {
    "match_all":{}
  },
  "size": 2,
  "search_after":[
    "4"
  ],
  "sort": [
    {"_id": {"order": "desc"}}
  ]
}'
```

如果数据量小（10000 条内），或者只关注结果集的 TopN 数据，可以使用 from/size 分页，简单粗暴。

数据量大，深度翻页，后台批处理任务（数据迁移）之类的任务，使用 scroll 方式。

数据量大，深度翻页，用户实时、高并发查询需求，使用 search after 方式。

The usage of Scroll API was useful to me, given that it stored state and worked with consistency data. But on a big amount of records - it had a very bad performance. And depend on timeout parameter, that unacceptable for my purposes. Search After API looks good, but anyway it stateless, so it can lead to data loss or duplication of records in the sample.

## 分布式机制

复杂分布式机制的透明隐藏特性：节点自动加入到集群上（集群名字相同）；集群将分片自动且均匀分配到各个节点，以保持节点均衡的读写负载请求；数据也会 reblance；节点的增加或减少会自动 reblance，即重分配分片；请求路由；集群扩容。

垂直扩容与水平扩容：垂直扩展，提升单机处理能力（增强单机硬件性能，提升单机架构性能）；水平扩展，增加服务器数量，就能线性扩充系统性能。

分片之间的主从关系：master 节点管理 es 集群的元数据，比如索引的创建个删除；维护索引元数据；节点的增加和移除；维护集群的元数据；默认情况下，会自动选择一个节点作为 master。

节点对等的分布式架构：每个节点的功能都一样，都能接收所有的请求；自动的请求路由；响应收集。

shard 和 replica：每个 index 包含多个 shard。每个 shard 都是一个最小的工作单元，承载部分数据、Lucene 实例、完整的建立索引和处理请求的能力。增减节点时，shard 会自动在节点中进行负载均衡。shard 和 replica，每个 document 只存在一个 shard 和它的 replica 当中。replica 是 shard 的数据副本，负责容错，以及承担读请求负载。shard 在创建索引的时候就固定了，而 replica 的数量可以更改。shard 默认是 5 个，replica 默认是 1 个，如果创建一个索引，则默认有 10 个分片。shard 不会和自己的 replica 放在同一个节点，不然无法起到容错作用。

## 并发控制

Elasticseach 基于 version 进行乐观锁的并发控制，对应的乐观锁的标识字段是 _version，是一个整数类型，一开始创建 document 时，_version 是等于 1 的，之后对 document 每修改一次，_version 版本号就会自动加 1。

其实所谓的乐观锁，根本就没有加锁，只是多了一标识字段，这个字段可以是一个整数类型的，也可以是时间类型的。主要的作用就是在每次修改数据的时候会做一层判断，判断数据是否已经被修改过了，如果已经被修改了，那么就会重新获取数据，在修改，这个过程不断进行知道数据修改成功。悲观锁就是在任何情况下都上锁，上锁之后，就只有一个线程可以操作这一条数据，其它线程只能等待，当然在不同的场景下，上的锁会有所不同，可以是行级锁，表级锁，读锁，写锁。通俗的来讲，加了悲观锁的话，对数据操作的时候就相当于是单线程的了。

## 练习

```shell
curl -H "Content-Type: application/json" -XPOST 'localhost:9200/_analyze?pretty' -d '{"analyzer":"ik_smart","text":" 王者农药 "}'

# curl 是一个命令行工具，通过 HTTP 协议传输数据
# -H 参数添加 HTTP 请求的表头，上例指定了 content-type
# -X 参数指定方法（GET，PUT 和 POST 等），一般省略 X 与参数之间的空格，默认 GET
# 在 URI 中跳过协议的指定，默认为 HTTP
# 在 URI 周围添加单引号，URI 可以包含多个参数，必须使用 & 符号分割不同的参数
# 用于 HTTP 请求的 URL 通常包含 pretty 或 pretty=true，否则默认应答在一行中显示
# -d 参数用于发送 POST 请求的数据体
```

```shell
curl -H "Content-Type: application/json" -XPUT 'localhost:9200/get-together/group/1?pretty' -d '{"name":"Elasticsearch Denver","orgainizer":"Lee"}'

{
  "_index" : "get-together",
  "_type" : "group",
  "_id" : "1",
  "_version" : 1,
  "result" : "created",
  "_shards" : {
    "total" : 2,
    "successful" : 1,
    "failed" : 0
  },
  "_seq_no" : 0,
  "_primary_term" : 1
}
# Es 自动创建了一个叫做 get-together 的索引，并为 group 类型创建了一个新的映射
````

```shell
curl -XPUT 'localhost:9200/new-index'

{"acknowledged":true,"shards_acknowledged":true,"index":"new-index"}
# 创建新索引
```

```shell
curl "localhost:9200/get-together/group,event/_search?q=elasticsearch&pretty"
# get-together 指定在哪个索引下搜索，多个索引使用逗号隔开
# group 和 event 指定在哪个类型下搜索，多个类型使用逗号隔开
# 如果在所有索引内搜索，可以使用 _all 作为占位符
# q=elasticsearch 指定了查询内容为 elasticsearch
{
  "took" : 1,
  "timed_out" : false,
  "_shards" : {
    "total" : 5,
    "successful" : 5,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : 2,
    "max_score" : 0.87138504,
    "hits" : [
      {
        "_index" : "get-together",
        "_type" : "group",
        "_id" : "2",
        "_score" : 0.87138504,
        "_source" : {
          "name" : "Elasticsearch Denver",
          "organizer" : "Lee",
          "description" : "Get together to learn more about using Elasticsearch, the applications and neat things you can do with ES!",
          "created_on" : "2013-03-15",
          "tags" : [
            "denver",
            "elasticsearch",
            "big data",
            "lucene",
            "solr"
          ],
          "members" : [
            "Lee",
            "Mike"
          ],
          "location_group" : "Denver, Colorado, USA"
        }
      },
      {
        "_index" : "get-together",
        "_type" : "group",
        "_id" : "3",
        "_score" : 0.2876821,
        "_source" : {
          "name" : "Elasticsearch San Francisco",
          "organizer" : "Mik",
          "description" : "Elasticsearch group for ES users of all knowledge levels",
          "created_on" : "2012-08-07",
          "tags" : [
            "elasticsearch",
            "big data",
            "lucene",
            "open source"
          ],
          "members" : [
            "Lee",
            "Igor"
          ],
          "location_group" : "San Francisco, California, USA"
        }
      }
    ]
  }
}
# took 耗时，单位毫秒； timed_out 搜索是否超时，可以在请求中添加 &timeout=3s 指定超时时间
# _shards 分片信息，在一个拥有 5 分片的索引中进行搜索，5 个分片成功返回
# hits 返回匹配的文档数组，total 和 max_score 是基本统计项

curl -H "Content-Type: application/json" "localhost:9200/get-together/group,event/_search?pretty" -d '{
  "query":{
    "query_string":{
      "query":"elasticsearch"
    }
  }
}'
# 运行一个类型为 query_string 的查询，字符串内容为 elasticsearch
{
  "took" : 2,
  "timed_out" : false,
  "_shards" : {
    "total" : 5,
    "successful" : 5,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : 2,
    "max_score" : 0.87138504,
    "hits" : [
      {
        "_index" : "get-together",
        "_type" : "group",
        "_id" : "2",
        "_score" : 0.87138504,
        "_source" : {
          "name" : "Elasticsearch Denver",
          "organizer" : "Lee",
          "description" : "Get together to learn more about using Elasticsearch, the applications and neat things you can do with ES!",
          "created_on" : "2013-03-15",
          "tags" : [
            "denver",
            "elasticsearch",
            "big data",
            "lucene",
            "solr"
          ],
          "members" : [
            "Lee",
            "Mike"
          ],
          "location_group" : "Denver, Colorado, USA"
        }
      },
      {
        "_index" : "get-together",
        "_type" : "group",
        "_id" : "3",
        "_score" : 0.2876821,
        "_source" : {
          "name" : "Elasticsearch San Francisco",
          "organizer" : "Mik",
          "description" : "Elasticsearch group for ES users of all knowledge levels",
          "created_on" : "2012-08-07",
          "tags" : [
            "elasticsearch",
            "big data",
            "lucene",
            "open source"
          ],
          "members" : [
            "Lee",
            "Igor"
          ],
          "location_group" : "San Francisco, California, USA"
        }
      }
    ]
  }
}

curl -H "Content-Type: application/json" "localhost:9200/get-together/group,event/_search?pretty" -d '{
  "query":{
    "query_string":{
      "query":"elasticsearch San Francisco",
      "default_field":"name",
      "default_operator":"AND"
    }
  }
}'
# default_name 指定查找的域; default_operator 默认为 OR，返回匹配了任意指定关键词的文档，AND 则为全匹配
{
  "took" : 8,
  "timed_out" : false,
  "_shards" : {
    "total" : 5,
    "successful" : 5,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : 1,
    "max_score" : 0.8630463,
    "hits" : [
      {
        "_index" : "get-together",
        "_type" : "group",
        "_id" : "3",
        "_score" : 0.8630463,
        "_source" : {
          "name" : "Elasticsearch San Francisco",
          "organizer" : "Mik",
          "description" : "Elasticsearch group for ES users of all knowledge levels",
          "created_on" : "2012-08-07",
          "tags" : [
            "elasticsearch",
            "big data",
            "lucene",
            "open source"
          ],
          "members" : [
            "Lee",
            "Igor"
          ],
          "location_group" : "San Francisco, California, USA"
        }
      }
    ]
  }
}

curl -H "Content-Type: application/json" "localhost:9200/get-together/group/_search?pretty" -d '{
  "query":{
    "term":{
      "name":"elasticsearch"
    }
  }
}'
# term 查询更直接和快速
{
  "took" : 1,
  "timed_out" : false,
  "_shards" : {
    "total" : 5,
    "successful" : 5,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : 2,
    "max_score" : 0.87138504,
    "hits" : [
      {
        "_index" : "get-together",
        "_type" : "group",
        "_id" : "2",
        "_score" : 0.87138504,
        "_source" : {
          "name" : "Elasticsearch Denver",
          "organizer" : "Lee",
          "description" : "Get together to learn more about using Elasticsearch, the applications and neat things you can do with ES!",
          "created_on" : "2013-03-15",
          "tags" : [
            "denver",
            "elasticsearch",
            "big data",
            "lucene",
            "solr"
          ],
          "members" : [
            "Lee",
            "Mike"
          ],
          "location_group" : "Denver, Colorado, USA"
        }
      },
      {
        "_index" : "get-together",
        "_type" : "group",
        "_id" : "3",
        "_score" : 0.2876821,
        "_source" : {
          "name" : "Elasticsearch San Francisco",
          "organizer" : "Mik",
          "description" : "Elasticsearch group for ES users of all knowledge levels",
          "created_on" : "2012-08-07",
          "tags" : [
            "elasticsearch",
            "big data",
            "lucene",
            "open source"
          ],
          "members" : [
            "Lee",
            "Igor"
          ],
          "location_group" : "San Francisco, California, USA"
        }
      }
    ]
  }
}

curl "localhost:9200/get-together/group/1?pretty"
# 查询指定 ID 的文档，同时需指定索引和类型
```
