# AOSP源码学习笔记

## sp、wp

Android设计了基类RefBase，用以管理引用数，所有类必须从RefBase派生，RefBase是所有对象的始祖。

设计模板类sp、wp，用以引用实际对象，sp强引用和wp弱引用。sp、wp声明为栈对象，作用域结束时，自动释放，自动调用析构函数。因此，可以在sp、wp的构造函数中，增引用数；在析构函数中，减少引用计数。

RefBase内部有一个指针指向实际对象，有一个weakref_impl类型的指针保存对象的强／弱引用计数、对象生命周期控制。sp只有一个成员变量，用来保存实际对象，但这个实际对象内部已包含了weakref_impl*对象用于保存实际对象的引用计数。sp管理一个对象指针时，对象的强、弱引用数同时加1，sp销毁时，对象的强、弱引用数同时减1。wp中有两个成员变量，一个保存实际对象，另一个是weakref_impl*对象。wp管理一个对象指针时，对象的弱引用计数加1，wp销毁时，对象的弱引用计数减1。

weakref_impl中包含一个flag用于决定对象的生命周期是由强引用数控制还是由弱引用数控制：

>- 当flag为0时，实际对象的生命周期由强引用数控制，weakref_impl*对象由弱引用数控制。
>- 当flag为OBJECT_LIFETIME_WEAK时，实际对象的生命周期受弱引用数控制。
>- 当flag为OBJECT_LIFETIME_FOREVER时，实际对象的生命周期由用户控制。
>- 可以用extendObjectLifetime改变flag的值。

## Handler、Looper、Message

Handler、Looper、Message这三者都与Android异步消息处理线程相关的概念。异步消息处理线程启动后会进入一个无限的循环体之中，每循环一次，从其内部的消息队列中取出一个消息，然后回调相应的消息处理函数，执行完成一个消息后则继续循环。若消息队列为空，线程则会阻塞等待。Looper负责的就是创建一个MessageQueue，然后进入一个无限循环体不断从该MessageQueue中读取消息，而消息的创建者就是一个或多个Handler。

## Android Meida

Android包含Stagefright。Stagefright是位于Native层的媒体播放引擎，内置了基于软件的编解码器，且适用于热门媒体格式。Stagefright音频和视频播放功能包括集成OpenMAX编解码器、会话管理、基于时间的同步渲染、传输控制和DRM。Stagefright还支持集成您提供的自定义硬件编解码器。要设置编码和解码媒体的硬件路径，您必须将基于硬件的编解码器作为OpenMax IL（集成层）组件进行实现。

媒体应用根据以下架构与Android Native多媒体框架进行交互。

应用代码位于应用框架层，可利用android.media API与多媒体硬件进行交互。

Binder IPC代理用于促进跨越进程边界的通信。它们位于frameworks/av/media/libmedia目录中，并以字母“I”开头。

在Native层，Android提供了一个利用Stagefright引擎进行音频和视频录制及播放的多媒体框架。Stagefright随附支持的软件编解码器的默认列表，并且您可以使用OpenMax集成层标准实现自己的硬件编解码器。有关实现的更多详细信息，请参阅位于frameworks/av/media中的MediaPlayer和Stagefright组件。

OpenMAX IL为Stagefright提供了一种标准化的方式来识别和使用基于硬件的自定义多媒体编解码器（称为组件）。必须以名为libstagefrighthw.so的共享库的形式提供OpenMAX插件。此插件将Stagefright与您的自定义编解码器组件相连接，并且该组件必须根据OpenMAX IL组件标准来实现。

为了提高设备安全性，Android 7.0 将整体的 mediaserver 进程分解为多个进程，同时仅向各个进程提供所需的权限和功能。旧版 Android 使用单个整体的 mediaserver 进程，该进程具有众多权限（相机访问权、音频访问权、视频驱动程序访问权、文件访问权、网络访问权等）。Android 7.0 将 mediaserver 进程拆分为几个新进程，这些进程要求的权限要少得多。

![MediaServer](../Resource/MediaServer.png)

### Media Codec

Android官方提供的音频编解码的API，即MediaCodec类，该API是在Andorid 4.1（API 16）版本引入的，因此只能工作于Android 4.1及以上的版本。

#### 基本介绍

>- 提供了一套访问Android底层多媒体模块的接口，主要是音视频的编解码接口。
>- Android底层多媒体模块采用的是OpenMax框架，任何Android底层编解码模块的实现，都必须遵循OpenMax标准。Google官方默认提供了一系列的软件编解码器：包括：OMX.google.h264.encoder，OMX.google.h264.encoder，OMX.google.aac.encoder，OMX.google.aac.decoder等等，而硬件编解码功能，则需要由芯片厂商依照OpenMax框架标准来完成，所以，一般采用不同芯片型号的手机，硬件编解码的实现和性能是不同的。
>- Android应用层统一由MediaCodec API来提供各种音视频编解码功能，由参数配置来决定采用何种编解码算法、是否采用硬件编解码加速等等。

#### 核心原理

MediaCodec使用的基本流程

```shell
createEncoderByType/createDecoderByType
configure
start
while(1) {
    dequeueInputBuffer
    queueInputBuffer
    dequeueOutputBuffer
    releaseOutputBuffer
}
stop
release
```

由此可以看到，Buffer队列的操作是其最核心的部分之一，关于MediaCodec的Buffer队列，示意图如下：

![MediaCodecBuffer](../Resource/MediaCodecBuffer.jpg)

MediaCodec架构上采用了2个缓冲区队列，异步处理数据，下面描述的Client和MediaCodec模块是并行工作的。

>-1. Client从input缓冲区队列申请empty buffer[dequeueInputBuffer]。
>-2. Client把需要编解码的数据拷贝到empty buffer，然后放入input缓冲区队列[queueInputBuffer]。
>-3. MediaCodec模块从input缓冲区队列取一帧数据进行编解码处理。
>-4. 编解码处理结束后，MediaCodec将原始数据buffer置为empty后放回input缓冲区队列，将编解码后的数据放入到output缓冲区队列。
>-5. Client从output缓冲区队列申请编解码后的buffer[dequeueOutputBuffer]。
>-6. Client对编解码后的buffer进行渲染/播放。
>-7. 渲染/播放完成后，Client再将该buffer放回output缓冲区队列[releaseOutputBuffer]。

MediaCodec在架构上，其实是采用了一种基于“环形缓冲区”的“生产者-消费者”模式，它设计了2个基于idx序号的“环形缓冲区”，注意，是2个，一个在input端，一个在output端。基于idx的环形缓冲区的总体示意图如下，图中，wp代表“写指针”，指向的是“emptybuffer”，rp代表“读指针”，指向的是“filled buffer”。

![BufferStruct](../Resource/BufferStruct.jpg)

“生产者”和“消费者”其实是共用这一个缓冲区队列，“生产者”负责从队列中取出未使用的Buffer，填入数据，然后放回队列，“消费者”则负责取出填入数据后的Buffer，进行处理，处理结束后，再把Buffer标记为“空”，退回到队列中去以供“生产者”继续填充数据。在input端，“Client”是这个环形缓冲区“生产者”，“MediaoCodec模块”是“消费者”。在output端，“MediaoCodec模块”是这个环形缓冲区“生产者”，而“Client”则变成了“消费者”。

### OpenMax

![OMX](../Resource/OMX1.png)

虚线中的内容是OpenMax IL层的内容，其主要实现了OpenMax IL中的各个组件（Component）。对下层，OpenMax IL可以调用OpenMax DL层的接口，也可以直接调用各种Codec实现。对上层，OpenMax IL可以给OpenMax AL 层等框架层（Middleware）调用，也可以给应用程序直接调用。
OpenMax IL主要内容如下所示。

客户端（Client）：OpenMax IL的调用者；
组件（Component）：OpenMax IL的单元，每一个组件实现一种功能；
端口（Port）：组件的输入输出接口；
隧道化（Tunneled）：让两个组件直接连接的方式；
组件、端口、隧道化思想和GStreamer (一种多媒体框架)中的 pipeline 十分类似。
Component实现单一功能、或是Source、Host、Accelerator和Sink。Port是Component对外的输入输出口。通过Tunneled将单一Component串联起来形成一个完整功能。OpenMax Core是辅助各个组件运行的部分。

OpenMax IL 的基本运作过程如图。

![OMX2](../Resource/OMX2.png)

openMAX IL的客户端，通过调用四个OpenMAX IL组件，实现了一个功能。四个组件分别是Source组件、Host组件、Accelerator组件和Sink组件。Source组件只有一个输出端口；而Host组件有一个输入端口和一个输出端口；Accelerator组件具有一个输入端口，调用了硬件的编解码器，加速主要体现在这个环节上。Accelerator组件和Sink组件通过私有通讯方式在内部进行连接，没有经过明确的组件端口。

OpenMAL IL在使用的时候，其数据流也有不同的处理方式：既可以经由客户端，也可以不经由客户端。图中，Source组件到Host组件的数据流就是经过客户端的；而Host组件到Accelerator组件的数据流就没有经过客户端，使用了隧道化的方式；Accelerator组件和Sink组件甚至可以使用私有的通讯方式。

OpenMax Core是辅助各个组件运行的部分，它通常需要完成各个组件的初始化等工作，在真正运行过程中，重点是各个OpenMax IL的组件，OpenMax Core不是重点，也不是标准。

OpenMAL IL的组件是OpenMax IL实现的核心内容，一个组件以输入、输出端口为接口，端口可以被连接到另一个组件上。外部对组件可以发送命令，还进行设置/获取参数、配置等内容。组件的端口可以包含缓冲区（Buffer）的队列。

组件的处理的核心内容是：通过输入端口消耗Buffer，通过输出端口填充Buffer，由此多组件相联接可以构成流式的处理。

![omxcomponent](../Resource/OMXcomponent.png)

组件的功能和其定义的端口类型密切相关，通常情况下：只有一个输出端口的，为Source组件；只有一个输入端口的，为Sink组件；有多个输入端口，一个输出端口的为Mux组件；有一个输入端口，多个输出端口的为DeMux组件；输入输出端口各一个组件的为中间处理环节，这是最常见的组件。
端口具体支持的数据也有不同的类型。例如，对于一个输入、输出端口各一个组件，其输入端口使用MP3格式的数据，输出端口使用PCM格式的数据，那么这个组件就是一个MP3解码组件。
隧道化（Tunneled）是一个关于组件连接方式的概念。通过隧道化可以将不同的组件的一个输入端口和一个输出端口连接到一起，在这种情况下，两个组件的处理过程合并，共同处理。尤其对于单输入和单输出的组件，两个组件将作为类似一个使用。

### Android中OMX的使用情况

Android系统的一些部分对OpenMax IL层进行使用，基本使用的是标准OpenMax IL层的接口，只是进行了简单的封装。标准的OpenMax IL实现很容易以插件的形式加入到Android系统中。Android的多媒体引擎OpenCore和StageFright都可以使用OpenMax作为多媒体编解码的插件，只是没有直接使用OpenMax IL层提供的纯C接口，而是对其进行了一定的封装(C++封装)。在Android2.x版本之后，Android的框架层也对OpenMax IL层的接口进行了封装定义，甚至使用Android中的Binder IPC机制。Stagefright使用了这个层次的接口，OpenCore没有使用。OpenCore使用OpenMax IL层作为编解码插件在前，Android框架层封装OpenMax接口在后面的版本中才引入。

### Android中OMX的实现内容

Android中使用的主要是OpenMax的编解码功能。虽然OpenMax也可以生成输入、输出、文件解析-构建等组件，但是在各个系统（不仅是Android）中使用的最多的还是编解码组件。媒体的输入、输出环节和系统的关系很大，引入OpenMax标准比较麻烦；文件解析-构建环节一般不需要使用硬件加速。编解码组件也是最能体现硬件加速的环节，因此最常使用。在Android中实现OpenMax IL层和标准的OpenMax IL层的方式基本，一般需要实现以下两个环节。

>- 编解码驱动程序：位于Linux内核空间，需要通过Linux内核调用驱动程序，通常使用非标准的驱动程序。
>- OpenMax IL层：根据OpenMax IL层的标准头文件实现不同功能的组件。

Android中还提供了OpenMax的适配层接口（对OpenMax IL的标准组件进行封装适配），它作为Android本地层的接口，可以被Android的多媒体引擎调用。

### OpenMax的接口与实现

OpenMax IL层的接口定义由若干个头文件组成。OpenMax标准只有头文件，没有标准的库，设置没有定义函数接口。对于实现者，需要实现的主要是包含函数指针的结构体。

其中，OMX_Component.h中定义的OMX_COMPONENTTYPE结构体是OpenMax IL层的核心内容，表示一个组件。OMX_COMPONENTTYPE结构体实现后，其中的各个函数指针就是调用者可以使用的内容。各个函数指针和OMX_core.h中定义的内容相对应。EmptyThisBuffer和FillThisBuffer是驱动组件运行的基本的机制，前者表示让组件消耗缓冲区，表示对应组件输入的内容；后者表示让组件填充缓冲区，表示对应组件输出的内容。UseBuffer，AllocateBuffer，FreeBuffer为和端口相关的缓冲区管理函数，对于组件的端口有些可以自己分配缓冲区，有些可以使用外部的缓冲区，因此有不同的接口对其进行操作。SendCommand表示向组件发送控制类的命令。GetParameter，SetParameter，GetConfig，SetConfig几个接口用于辅助的参数和配置的设置和获取。 ComponentTunnelRequest用于组件之间的隧道化连接，其中需要制定两个组件及其相连的端口。ComponentDeInit用于组件的反初始化。OpenMax函数的参数中，经常包含OMX_IN和OMX_OUT等宏，它们的实际内容为空，只是为了标记参数的方向是输入还是输出。OMX_Component.h中端口类型的定义为OMX_PORTDOMAINTYPE枚举类型。音频类型，视频类型，图像类型，其他类型是OpenMax IL层此所定义的四种端口的类型。端口具体内容的定义使用OMX_PARAM_PORTDEFINITIONTYPE类（也在OMX_Component.h中定义）来表示。对于一个端口，其重点的内容有：端口的方向（OMX_DIRTYPE），包含OMX_DirInput（输入）和OMX_DirOutput（输出）两种；端口分配的缓冲区数目和最小缓冲区数目；端口的类型（OMX_PORTDOMAINTYPE），可以是四种类型；端口格式的数据结构，使用format联合体来表示，具体由四种不同类型来表示，与端口的类型相对应 OMX_AUDIO_PORTDEFINITIONTYPE，OMX_VIDEO_PORTDEFINITIONTYPE，OMX_IMAGE_PORTDEFINITIONTYPE和OMX_OTHER_PORTDEFINITIONTYPE等几个具体的格式类型，分别在OMX_Audio.h，OMX_Video.h，OMX_Image.h和OMX_Other.h这四个头文件中定义。OMX_BUFFERHEADERTYPE是在OMX_Core.h中定义的，表示一个缓冲区的头部结构。OMX_Core.h中定义的枚举类型OMX_STATETYPE命令表示OpenMax的状态机。

对于OpenMax IL层的实现，一般的方式并不调用OpenMax DL层。具体实现的内容就是各个不同的组件。OpenMax IL组件的实现包含以下两个步骤。

>- 组件的初始化函数：硬件和OpenMax数据结构的初始化，一般分成函数指针初始化、私有数据结构的初始化、端口的初始化等几个步骤，使用其中的pComponentPrivate成员保留本组件的私有数据为上下文，最后获得填充完成OMX_COMPONENTTYPE类型的结构体。
>- OMX_COMPONENTTYPE类型结构体的各个指针实现：实现其中的各个函数指针，需要使用私有数据的时候，从其中的pComponentPrivate得到指针，转化成实际的数据结构使用。端口的定义是OpenMax IL组件对外部的接口。OpenMax IL常用的组件大都是输入和输出端口各一个。对于最常用的编解码（Codec）组件，通常需要在每个组件的实现过程中，调用硬件的编解码接口来实现。在组件的内部处理中，可以建立线程来处理。OpenMax的组件的端口有默认参数，但也可以在运行时设置，因此一个端口也可以支持不同的编码格式。音频编码组件的输出和音频编码组件的输入通常是原始数据格式（PCM格式），视频编码组件的输出和视频编码组件的输入通常是原始数据格式（YUV格式）。

在一种特定的硬件实现中，编解码部分具有相似性，因此通常可以构建一个OpenMax组件的”基类”或者公共函数，来完成公共性的操作。
Android中OpenMax的适配层

Android中的OpenMax适配层的接口在frameworks/base/include/media/目录中的IOMX.h文件定义。IOMX表示的是OpenMax的一个组件，根据Android的Binder IPC机制，BnOMX继承IOMX，实现者需要继承实现BnOMX。IOMX类中，除了和标准的OpenMax的GetParameter，SetParameter，GetConfig，SetConfig，SendCommand，UseBuffer，AllocateBuffer，FreeBuffer，FillThisBuffer和EmptyThisBuffer等接口之外，还包含了创造渲染器的接口createRenderer()，创建的接口为IOMXRenderer类型。IOMX中只有第一个createRenderer()函数是纯虚函数，第二个的createRenderer()函数和createRendererFromJavaSurface()通过调用第一个createRenderer()函数实现。IOMXRenderer类表示一个OpenMax的渲染器。IOMXRenderer只包含了一个render接口，其参数类型IOMX::buffer_id实际上是void*，根据不同渲染器使用不同的类型。在IOMX.h文件中，另有表示观察器类的IOMXObserver，这个类表示OpenMax的观察者，其中只包含一个onMessage()函数，其参数为omx_message接口体，其中包含Event事件类型、FillThisBuffer完成和EmptyThisBuffer完成几种类型。Android中OpenMax的适配层是OpenMAX IL层至上的封装层，在Android系统中被StageFright调用，也可以被其他部分调用。

![decodeSample](../Resource/OMXdecodeAAC.png)