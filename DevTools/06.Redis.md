# Redis 数据库

## 导读

与传统数据库相比，Redis的数据是存在内存中的，所以存写速度非常快，因此Redis被广泛应用于缓存方向。另外，Redis也经常用来做分布式锁。Redis提供了多种数据类型来支持不同的业务场景。除此之外，Redis支持事务、持久化、LUA脚本、LRU驱动事件、多种集群方案。

## 为什么要用Redis/为什么要用缓存

### 高性能

假如用户第一次访问数据库中的某些数据。这个过程会比较慢，因为是从硬盘上读取的。将该用户访问的数据存在缓存中，这样下一次再访问这些数据的时候就可以直接从缓存中获取了。操作缓存就是直接操作内存，所以速度相当快。如果数据库中的对应数据改变了之后，同步改变缓存中相应的数据即可。

![image](../Resource/Redis01.jpg)

### 高并发

直接操作缓存能够承受的请求是远远大于直接访问数据库的，可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。

![image](../Resource/Redis02.png)

## 为什么要用Redis而不用map/guava做缓存

缓存分为本地缓存和分布式缓存。以Java为例，使用自带的map或者guava实现的是本地缓存，最主要的特点是轻量以及快速，生命周期随着JVM的销毁而结束。并且在多实例的情况下，每个实例都需要各自保存一份缓存，缓存不具有一致性。使用Redis或Memcached之类的称为分布式缓存，在多实例的情况下，各实例共用一份缓存数据，缓存具有一致性。缺点是需要保持Redis或Memcached服务的高可用，整个程序架构上较为复杂。

## Redis和Memcached的区别

>- Redis支持更丰富的数据类型，支持更复杂的应用场景。Redis不仅仅支持简单的K/V类型的数据，同时还提供list、set、zset、hash等数据结构的存储。Memcache支持简单的数据类型String。
>- Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。Memecache把数据全部存在内存之中。
>- Redis目前原生支持Cluster模式。Memcached没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据。
>- Memcached是多线程，非阻塞IO复用的网络模型。Redis使用单线程的多路IO复用模型。

![image](../Resource/Redis&Memcached.jpg)

## Redis常见数据结构以及使用场景分析

```shell
SET [key] [value]
GET [key]
DUMP [key]   // 序列化给定的key，返回序列化的值
EXISTS [key]
EXPIRE [key] seconds // 设置过期时间，以秒计
EXPIREAT [key] [timestamp]  // 设置过期时间戳
PERSIST [key] // 移除过期时间，永久保持
TTL [key] // 返回过期时间，以秒计
KEYS [pattern]  // 查找所有符合给定模式( pattern)的 key
RENAME [key] [newkey] // 修改key的名称
RENAMENX [key] [newkey] // 修改key的名称，仅当newkey不存在时
```

String。常用命令：set、get、decr、incr、mget等。String数据结构是简单的Key-Value类型，Value其实不仅可以是String，也可以是数字。string 类型是二进制安全的。意思是Redis的String可以包含任何数据。比如jpg图片或者序列化的对象。String类型是Redis最基本的数据类型，String类型的值最大能存储512MB。常规Key-Value缓存应用；常规计数：微博数，粉丝数等。

```shell
MGET [key1] [key2] [key3]
SETNX [key] [value]  // 只有在key不存在时设置key的值
INCR [key]  //  将key中储存的数字值增一
INCR [key] [inc] //  将key中储存的数字值增加指定的值
INCRBYFLOAT [key] [inc] // 增量为浮点值
DECR [key]  //  将key中储存的数字值增一
DECR [key] [inc] //  将key中储存的数字值增加指定的值
APPEND [key] [value] // 字符串的value追加内容
```

Hash。常用命令：hget、hset、hgetall等。Hash是一个String类型的Field和Value的映射表，Hash特别适合用于存储对象。每个hash可以存储2^32-1键值对（40多亿）后续操作时可以直接仅仅修改这个对象中的某个字段的值。比如可以Hash数据结构来存储用户信息，商品信息等等。在做单点登录的时候，就是用这种数据结构存储用户信息，以cookieId作为key，设置30分钟为缓存过期时间，能很好的模拟出类似session的效果。

```shell
HMSET [hash_name-key] [field1] [value] [field2] [value] [field3] [value]
HGET [hash_name-key] [field]
HDEL [hash_name-key] [field1] [field2]
HGETALL [hash_name-key] // 获取在哈希表的所有字段和值
HINCRBY [hash_name-key] [field] [incr]
HINCRBYFLOAT [hash_name-key] [field] [incr]
HLEN [key] // field的数量
```

List。常用命令：lpush、rpush、lpop、rpop、lrange等。List就是链表，可以添加一个元素到列表的头部（左边）或者尾部（右边）。Redis List的应用场景非常多，也是Redis最重要的数据结构之一。比如微博的关注列表，粉丝列表，消息列表等功能都可以用Redis的List结构来实现。RedisList的实现为一个双向链表，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销。另外可以通过lrange命令，就是从某个元素开始读取多少个元素，可以基于List实现分页查询。这是很棒的一个功能，基于Redis实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西（一页一页的往下走）。

```shell
LPUSH [list_name-key] [value]
RPOP [list_name-key]
LRANGE [list_name-key] [begin_idx] [end_idx]
BLPOP [list_name-key1] [list_name-key2] [timeout] // 移出并获取列表第一个元素，没有会阻塞或者等到超时
BRPOP [list_name-key1] [list_name-key2] [timeout] // 移出并获取列表最后一个元素，没有会阻塞或者等到超时
LINDEX [list_name-key] [index] // 通过索引获得value
LINSERT [list_name-key] [BEFORE|AFTER] [pivot] [value] 在列表的元素前或者后插入元素
```

Set。无序集合，集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是 O(1)。。常用命令：sadd、spop、smembers、sunion等。Set对外提供的功能与List类似是一个列表的功能，特殊之处在于Set是可以自动去重的。当需要存储一个列表数据，又不希望出现重复数据时，Set是一个很好的选择。并且Set提供了判断某个成员是否在一个Set集合内的重要接口，这个也是List所不能提供的。可以基于Set轻易实现交集、并集、差集的操作。比如：在微博应用中，可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。Redis可以非常方便的实现如共同关注、共同粉丝、共同喜好等功能。为什么不用JVM自带的Set进行去重？因为系统一般都是集群部署，使用JVM自带的Set，比较麻烦，难道为了一个做一个全局去重，再起一个公共服务？

```shell
SADD [set_name-key] [member]
SMEMBERS [set_name-key]
SCARD [set_name-key]  //  成员数
SISMEMBER [set_name-key] [member]  // 判断member元素是否是集合成员
SPOP [set_name-key]  // 移除并返回集合中的一个随机元素
SREM [set_name-key] [member1] [member2]   //  移除集合中一个或多个成员
SSCAN [set_name-key] [cursor] [MATCH pattern] [COUNT count] // 迭代集合中的元素
```

SortedSet。 zset和set一样也是string类型元素的集合，且不允许重复的成员。
不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。常用命令：zadd、zrange、zrem、zcard等。和Set相比，SortedSet增加了一个权重参数Score，使得集合中的元素能够按Score进行有序排列。可以做排行榜应用，取TOPN操作。sortedset可以用来做延时任务。最后一个应用就是可以做范围查找。举例：在直播系统中，实时排行信息包含直播间在线用户列表，各种礼物排行榜，弹幕消息（可以理解为按消息维度的消息排行榜）等信息，适合使用Redis中的SortedSet结构进行存储。

```shell
ZADD [zset_name-key] [score] [member]
ZRANGE [zset_name-key] [begin_idx] [end_idx] [WITHSCORES]  //  通过索引区间返回有序集合指定区间内的成员
ZRANGEBYLEX [zset_name-key] [min] [max] [LIMIT offset count] // 通过字典区间返回有序集合的成员
ZRANGEBYSCORE [zset_name-key] [min] [max] [WITHSCORES] [LIMIT]  // 通过分数返回有序集合指定区间内的成员
ZCARD [zset_name-key]  //  获取有序集合的成员数
ZCOUNT [zset_name-key] [min] [max]   // 计算在有序集合中指定区间分数的成员数
ZRANK [zset_name-key] [member]  //  返回有序集合中指定成员的索引
ZREVRANK [zset_name-key] [member]  //  返回有序集合中指定成员的排名（逆序，从大到小）
ZREM [zset_name-key] [member1] [member2]   // 移除有序集合中的一个或多个成员
ZINCRBY [zset_name-key] [inc] [member]  //  有序集合中对指定成员的分数加上增量
ZSCORE [zset_name-key] [member]  // 返回有序集中，成员的分数值
```

## Redis设置过期时间

Redis中有个设置过期时间的功能，即对存储在Redis数据库中的值可以设置一个过期时间。作为一个缓存数据库，这是非常实用的。比如一般项目中的Token或者一些登录信息，尤其是短信验证码都是有时间限制的，按照传统的数据库处理方式，一般都是自己判断过期，这样无疑会严重影响项目性能。在SetKey的时候，都可以给一个ExpireTime，即过期时间，通过过期时间我们可以指定这个Key可以存活的时间。如果设置了一批Key只能存活1个小时，那么接下来1小时后，Redis是怎么对这批Key进行删除的？答案是：定期删除+惰性删除。

>- 定期删除：Redis默认是每隔100ms就随机抽取一些设置了过期时间的Key，检查其是否过期，如果过期就删除。为什么要随机呢？假如Redis存了几十万个Key，每隔100ms就遍历所有的设置过期时间的Key的话，就会给CPU带来很大的负载。
>- 惰性删除：定期删除可能会导致很多过期Key到了时间并没有被删除掉。所以就有了惰性删除。假如过期Key，靠定期删除没有被删除掉，还停留在内存里。当系统去查一下那个Key，发现key过期才会删掉。

但是仅仅通过设置过期时间还是有问题的。如果定期删除漏掉了很多过期Key，惰性删除也漏掉了这些key，那么有可能大量过期Key堆积在内存里导致Redis内存块耗尽。怎么解决这个问题呢？内存淘汰机制。

## Redis内存淘汰机制

Redis提供6种数据淘汰策略：

>- volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰。
>- volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰。
>- volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰。
>- allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key（这个是最常用的）。
>- allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰。
>- no-enviction：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！

## Redis持久化机制

怎么保证Redis挂掉之后再重启数据可以进行恢复？很多时候需要持久化数据也，就是将内存中的数据写入到硬盘里面。大部分原因是为了之后重用数据（比如重启机器、机器故障之后恢复数据），或者是为了防止系统故障而将数据备份到一个远程位置。Redis不同于Memcached的很重要一点就是，Redis支持持久化，而且支持两种不同的持久化操作。Redis的一种持久化方式叫快照（snapshotting，RDB），另一种方式是只追加文件（append-onlyfile，AOF）。

### 快照（snapshotting）持久化（RDB）

Redis可以通过创建快照来获得存储在内存里面的数据在某个时间点上的副本。Redis创建快照之后，可以对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis主从结构，主要用来提高Redis性能），还可以将快照留在原地以便重启服务器的时候使用。快照持久化是Redis默认采用的持久化方式，在Redis.conf配置文件中默认有此下配置：

```shell
 # 在900秒(15分钟)之后，如果至少有1个key发生变化，Redis就会自动触发BGSAVE命令创建快照。
save 900 1
# 在300秒(5分钟)之后，如果至少有10个key发生变化，Redis就会自动触发BGSAVE命令创建快照。
save 300 10
```

### AOF（append-only file）持久化

与快照持久化相比，AOF持久化的实时性更好，已成为主流的持久化方案。默认情况下Redis没有开启AOF（append only file）方式的持久化，可以通过appendonly参数开启：

```shell
appendonly yes
```

开启AOF持久化后每执行一条会更改Redis中的数据的命令，Redis就会将该命令写入硬盘中的AOF文件。AOF文件的保存位置和RDB文件的位置相同，都是通过dir参数设置的，默认的文件名是appendonly.aof。在Redis的配置文件中存在三种不同的AOF持久化方式，它们分别是：

>- appendfsync always。每次有数据修改发生时都会写入AOF文件，这样会严重降低Redis的速度。
>- appendfsync everysec。每秒钟同步一次，显示地将多个写命令同步到硬盘。
>- appendfsync no。让操作系统决定何时进行同步。

为了兼顾数据和写入性能，用户可以考虑appendfsynceverysec选项，让Redis每秒同步一次AOF文件，Redis性能几乎没受到任何影响。而且这样即使出现系统崩溃，用户最多只会丢失一秒之内产生的数据。当硬盘忙于执行写入操作的时候，Redis还会优雅的放慢自己的速度以便适应硬盘的最大写入速度。

### Redis4.0对于持久化机制的优化

Redis4.0开始支持RDB和AOF的混合持久化（默认关闭，可以通过配置项aof-use-rdb-preamble开启）。如果把混合持久化打开，AOF重写的时候就直接把RDB的内容写到AOF文件开头。这样做的好处是可以结合RDB和AOF的优点,快速加载同时避免丢失过多的数据。当然缺点也是有的，AOF里面的RDB部分是压缩格式不再是AOF格式，可读性较差。

### 补充内容：AOF重写

AOF重写可以产生一个新的AOF文件，这个新的AOF文件和原有的AOF文件所保存的数据库状态一样，但体积更小。AOF重写是一个有歧义的名字，该功能是*通过读取数据库中的键值对来实现的，程序无须对现有AOF文件进行任伺读入、分析或者写入操作*。在执行BGREWRITEAOF命令时，Redis服务器会维护一个AOF重写缓冲区，该缓冲区会在子进程创建新AOF文件期间，记录服务器执行的所有写命令。当子进程完成创建新AOF文件的工作之后，服务器会将重写缓冲区中的所有内容追加到新AOF文件的末尾，使得新旧两个AOF文件所保存的数据库状态一致。最后，服务器用新的AOF文件替换旧的AOF文件，以此来完成AOF文件重写操作。

### Redis事务

Redis通过MULTI、EXEC、WATCH等命令来实现事务(transaction)功能。事务提供了一种将多个命令请求打包，然后一次性、按顺序地执行多个命令的机制。并且在事务执行期间，服务器不会中断事务而改去执行其他客户端的命令请求，它会将事务中的所有命令都执行完毕，然后才去处理其他客户端的命令请求。在传统的关系式数据库中，常常用ACID性质来检验事务功能的可靠性和安全性。在Redis中，事务总是具有原子性（Atomicity)、一致性(Consistency)和隔离性（Isolation），并且当Redis运行在某种特定的持久化模式下时，事务也具有持久性（Durability）。

Redis 事务可以一次执行多个命令， 并且带有以下三个重要的保证：

>- 批量操作在发送 EXEC 命令前被放入队列缓存。
>- 收到 EXEC 命令后进入事务执行，事务中任意命令执行失败，其余的命令依然被执行。
>- 在事务执行过程，其他客户端提交的命令请求不会插入到事务执行命令序列中。

单个 Redis 命令的执行是原子性的，但 Redis 没有在事务上增加任何维持原子性的机制，所以 Redis 事务的执行并不是原子性的。事务可以理解为一个打包的批量执行脚本，但批量指令并非原子化的操作，中间某条指令的失败不会导致前面已做指令的回滚，也不会造成后续的指令不做。所以挺垃圾的。

## 缓存雪崩和缓存穿透问题解决方案

### 缓存雪崩

缓存同一时间大面积的失效，所以后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。

>- 使用互斥锁，但是该方案吞吐量明显下降了。
>- 给缓存的失效时间，加上一个随机值，避免集体失效。
>- 双缓存。比如有两个缓存，A和B。缓存A的失效时间为20分钟，缓存B不设失效时间。自己做缓存预热操作。从缓存A读数据库，有则直接返回。A没有数据，直接从B读数据，直接返回，并且异步启动一个更新线程。更新线程同时更新缓存A和缓存B。

### 缓存穿透

一般是黑客故意去请求缓存中不存在的数据，导致所有的请求都落到数据库上，造成数据库短时间内承受大量请求而崩掉。

>- 利用互斥锁，缓存失效的时候，先去获得锁，得到锁了，再去请求数据库。没得到锁，则休眠一段时间重试。
>- 采用异步更新策略，无论key是否取到值，都直接返回。value值中维护一个缓存失效时间，缓存如果过期，异步起一个线程去读数据库，更新缓存。需要做缓存预热(项目启动前，先加载缓存)操作。
>- 提供一个能迅速判断请求是否有效的拦截机制，比如利用布隆过滤器，内部维护一系列合法有效的key。迅速判断出请求所携带的Key是否合法有效。如果不合法则直接返回。

## 如何解决Redis的并发竞争Key问题

所谓Redis的并发竞争Key的问题也就是多个系统同时对一个Key进行操作，但是最后执行的顺序和我们期望的顺序不同，这样也就导致了结果的不同。

推荐一种方案：分布式锁（ZooKeeper和Redis都可以实现分布式锁）。如果不存在Redis的并发竞争Key问题，不要使用分布式锁，这样会影响性能。基于ZooKeeper临时有序节点可以实现的分布式锁。

每个客户端对某个方法加锁时，在ZooKeeper上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。当释放锁的时候，只需将这个瞬时节点删除即可。同时可以避免服务宕机导致的锁无法释放，而产生的死锁问题。完成业务流程后，删除对应的子节点释放锁。在实践中，当然是以可靠性为主，所以首推ZooKeeper。

## Redis和数据库双写一致性问题

一致性问题是分布式常见问题，还可以再分为最终一致性和强一致性。数据库和缓存双写，就必然会存在不一致的问题。如果对数据有强一致性要求，就不能放缓存。我们所做的一切，只能保证最终一致性。另外，我们所做的方案其实从根本上来说，只能说降低不一致发生的概率，无法完全避免。因此，有强一致性要求的数据，不能放缓存。

首先，采取正确更新策略，先更新数据库，再删缓存。其次，因为可能存在删除缓存失败的问题，提供一个补偿措施即可，例如利用消息队列。
